{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Francisco Dominguez Mateos\n",
    "# 27/06/2020\n",
    "# NOTHING working in here\n",
    "# Defining a custom layer\n",
    "#!conda install -c conda-forge opencv --yes\n",
    "#!conda install -c anaconda tensorflow-gpu --yes\n",
    "#!conda install -c conda-forge tensorflow-probability --yes\n",
    "#!conda install -c conda-forge tensorboard --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "from jax.nn import relu, log_softmax\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import BatchNorm, Dense, Relu, LogSoftmax\n",
    "from jax.experimental.stax import Conv, Flatten, elementwise\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key which is used to generate random numbers\n",
    "rng = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def Reshape(newshape):\n",
    "#  \"\"\"Layer construction function for a reshape layer.\"\"\"\n",
    "#  init_fun = lambda rng, input_shape: (newshape,())\n",
    "#  apply_fun = lambda params, inputs, **kwargs: jnp.reshape(inputs,newshape)\n",
    "#  return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reshape(new_shape):\n",
    "    def init_func(rng,input_shape):\n",
    "        ''' there is not weight just change shape'''\n",
    "        if new_shape[0]==-1:\n",
    "            rnew_shape=input_shape[0:1]+new_shape[1:]\n",
    "        else:\n",
    "            rnew_shape=new_shape\n",
    "        return (rnew_shape,())\n",
    "    def apply_func(params,inputs,**kwargs):\n",
    "        return np.reshape(inputs,new_shape)\n",
    "    return init_func,apply_func\n",
    "LogSoftmax2D=elementwise(log_softmax, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "init_mlp, mlp = stax.serial(Conv(32, (5, 5), (2, 2), padding=\"SAME\"),\n",
    "                            #BatchNorm(), #doesn't seem to work with Dense!!!\n",
    "                            Relu,\n",
    "                            Flatten,\n",
    "                            Dense(28*28),\n",
    "                            Reshape((-1,1,28,28)),\n",
    "                            LogSoftmax2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99988556 4.2438507e-05\n",
      "(100, 1, 10, 10)\n",
      "pred= (100, 1, 28, 28)\n",
      "-4.4202785 -4.7591043\n",
      "lsm= (100, 1, 28, 28)\n",
      "-4.4202785 -4.7591043\n"
     ]
    }
   ],
   "source": [
    "# Very interesting if we put another dimension 20 in this case\n",
    "# the model is repeated 20 times and output 20 times num_classes\n",
    "in_shape = (100, 1,10,10)\n",
    "output_shape, params = init_mlp(rng, in_shape)\n",
    "fake_data=random.uniform(rng,in_shape)\n",
    "print(np.max(fake_data),np.min(fake_data))\n",
    "print(fake_data.shape)\n",
    "pred=mlp(params,fake_data)\n",
    "print(\"pred=\",pred.shape)\n",
    "print(np.max(pred),np.min(pred))\n",
    "lsm=log_softmax(pred,axis=0)\n",
    "print(\"lsm=\",lsm.shape)\n",
    "print(np.max(lsm),np.min(lsm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.4834404 -4.7264633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4080eb4a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=np.reshape(pred[0],(28,28))\n",
    "print(np.max(img),np.min(img))\n",
    "plt.imshow(img,cmap='gray',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Siren(s=[1000]*5,w0=30.0):\n",
    "    def init_fun(key,input_shape):\n",
    "        \"\"\" Initialize the weights of all layers of a linear layer network \"\"\"\n",
    "        sizes=[input_shape[-1]]+s\n",
    "        print(sizes)\n",
    "        keys = random.split(key, len(sizes))\n",
    "        # Initialize a single layer with Gaussian weights -  helper function\n",
    "        def initialize_layer(m, n, rng):\n",
    "            scale=np.sqrt(6.0/float(m))\n",
    "            w_key, b_key = random.split(key)\n",
    "            return scale * random.uniform(w_key, (n, m),minval=-1.0, maxval=1.0),scale * random.uniform(b_key, (n,  ),minval=-1.0, maxval=1.0)\n",
    "        # actually they are pairs plus the random key\n",
    "        pairs=zip(sizes[:-1], sizes[1:], keys)\n",
    "        params=[initialize_layer(m, n, k) for m, n, k in pairs]\n",
    "        # first layer is scalled by w0\n",
    "        params[0]=params[0][0]*w0,params[0][1]\n",
    "        output_shape =  input_shape[:-1] + (sizes[-1],)\n",
    "        return (output_shape,params)\n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        \"\"\" Compute the forward pass for each example individually \"\"\"\n",
    "        activations = inputs\n",
    "        # Loop over the Siren hidden layers\n",
    "        for w, b in params:\n",
    "            linear = np.dot(w,activations)+b\n",
    "            activations=np.sin(linear)\n",
    "        return activations\n",
    "    return init_fun, apply_fun      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU(out_dim, W_init=glorot_normal(), b_init=normal()):\n",
    "    def init_fun(rng, input_shape):\n",
    "        \"\"\" Initialize the GRU layer for stax \"\"\"\n",
    "        hidden = b_init(rng, (input_shape[0], out_dim))\n",
    "\n",
    "        k1, k2, k3 = random.split(rng, num=3)\n",
    "        update_W, update_U, update_b = (\n",
    "            W_init(k1, (input_shape[2], out_dim)),\n",
    "            W_init(k2, (out_dim, out_dim)),\n",
    "            b_init(k3, (out_dim,)),)\n",
    "\n",
    "        k1, k2, k3 = random.split(rng, num=3)\n",
    "        reset_W, reset_U, reset_b = (\n",
    "            W_init(k1, (input_shape[2], out_dim)),\n",
    "            W_init(k2, (out_dim, out_dim)),\n",
    "            b_init(k3, (out_dim,)),)\n",
    "\n",
    "        k1, k2, k3 = random.split(rng, num=3)\n",
    "        out_W, out_U, out_b = (\n",
    "            W_init(k1, (input_shape[2], out_dim)),\n",
    "            W_init(k2, (out_dim, out_dim)),\n",
    "            b_init(k3, (out_dim,)),)\n",
    "        # Input dim 0 represents the batch dimension\n",
    "        # Input dim 1 represents the time dimension (before scan moveaxis)\n",
    "        output_shape = (input_shape[0], input_shape[1], out_dim)\n",
    "        return (output_shape,\n",
    "            (hidden,\n",
    "             (update_W, update_U, update_b),\n",
    "             (reset_W, reset_U, reset_b),\n",
    "             (out_W, out_U, out_b),),)\n",
    "\n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        \"\"\" Loop over the time steps of the input sequence \"\"\"\n",
    "        h = params[0]\n",
    "\n",
    "        def apply_fun_scan(params, hidden, inp):\n",
    "            \"\"\" Perform single step update of the network \"\"\"\n",
    "            _, (update_W, update_U, update_b), (reset_W, reset_U, reset_b), (\n",
    "                out_W, out_U, out_b) = params\n",
    "\n",
    "            update_gate = sigmoid(np.dot(inp, update_W) +\n",
    "                                  np.dot(hidden, update_U) + update_b)\n",
    "            reset_gate = sigmoid(np.dot(inp, reset_W) +\n",
    "                                 np.dot(hidden, reset_U) + reset_b)\n",
    "            output_gate = np.tanh(np.dot(inp, out_W)\n",
    "                                  + np.dot(np.multiply(reset_gate, hidden), out_U)\n",
    "                                  + out_b)\n",
    "            output = np.multiply(update_gate, hidden) + np.multiply(1-update_gate, output_gate)\n",
    "            hidden = output\n",
    "            return hidden, hidden\n",
    "\n",
    "        # Move the time dimension to position 0\n",
    "        inputs = np.moveaxis(inputs, 1, 0)\n",
    "        f = partial(apply_fun_scan, params)\n",
    "        _, h_new = lax.scan(f, h, inputs)\n",
    "        return h_new\n",
    "\n",
    "    return init_fun, apply_fun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
