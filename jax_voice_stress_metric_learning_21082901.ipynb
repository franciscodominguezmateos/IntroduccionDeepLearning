{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "protected-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Francisco Dominguez Mateos\n",
    "# 29/08/2021\n",
    "# Voice Stress detection\n",
    "# Dimension reduction with Deep Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sacred-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "#np.set_printoptions(precision=3)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "informational-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base=\"/home/francisco/datasets/datasets/sound/voice/stress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "meaning-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return 1.0\n",
    "    if s==\"FALSE\":\n",
    "        return 0.0\n",
    "    if s==\"PC\":\n",
    "        return 2.0\n",
    "def isRightLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return True\n",
    "    if s==\"FALSE\":\n",
    "        return True\n",
    "    if s==\"PC\":\n",
    "        return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "spoken-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Males.csv\n",
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Females.csv\n",
      "(50, 68)\n",
      "[[126.278 0.014 0.029 ... 15.681 0.870 0.012]\n",
      " [142.901 0.005 0.019 ... 10.834 0.936 0.008]\n",
      " [117.189 0.005 0.014 ... 11.765 0.967 0.006]\n",
      " ...\n",
      " [192.269 0.008 0.022 ... 10.600 0.928 0.007]\n",
      " [167.700 0.005 0.025 ... 9.564 0.933 0.009]\n",
      " [206.086 0.007 0.013 ... 9.851 0.922 0.046]]\n",
      "(50,)\n",
      "[1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "file_txt=path_base+\"/*.csv\"\n",
    "for filepath in glob.glob(file_txt):\n",
    "    print(\"Processing file: {}\".format(filepath)) \n",
    "    with open(filepath) as fp:  \n",
    "        line = fp.readline()\n",
    "        head_list=line.split(\";\")\n",
    "        #for i,head in enumerate(head_list):\n",
    "        #    print(i,head)\n",
    "        cnt = 1\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            data_row=[]\n",
    "            line_list=line.split(\";\")\n",
    "            #print(\"Line {}: {} {} {}\".format(cnt, line_list[0], line_list[1], line_list[2]))\n",
    "            line = fp.readline()\n",
    "            cnt += 1\n",
    "            if not isRightLabel(line_list[0]):\n",
    "                continue\n",
    "            for i,datum in enumerate(line_list):\n",
    "                #print(i,head_list[i],\"=\",datum)\n",
    "                if i>1:\n",
    "                    data_row.append(float(datum))\n",
    "                if i==0:\n",
    "                    labels.append(getLabel(datum))\n",
    "            data.append(data_row)\n",
    "data_np=np.array(data)\n",
    "labels_np=np.array(labels)\n",
    "print(data_np.shape)\n",
    "print(data_np)\n",
    "print(labels_np.shape)\n",
    "print(labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "stuck-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "banner-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 68)\n",
      "[[-0.692 1.335 0.942 ... 1.056 -1.550 -0.524]\n",
      " [-0.309 -0.907 -0.100 ... -0.261 0.011 -0.808]\n",
      " [-0.901 -0.907 -0.621 ... -0.008 0.744 -0.950]\n",
      " ...\n",
      " [0.826 -0.159 0.213 ... -0.325 -0.178 -0.879]\n",
      " [0.261 -0.907 0.525 ... -0.606 -0.060 -0.737]\n",
      " [1.144 -0.409 -0.725 ... -0.528 -0.320 1.895]]\n"
     ]
    }
   ],
   "source": [
    "ss=StandardScaler()\n",
    "data_ss=ss.fit_transform(data_np)\n",
    "\n",
    "print(data_ss.shape)\n",
    "print(data_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "suitable-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 2, 2)\n",
      "(1225,)\n"
     ]
    }
   ],
   "source": [
    "def buildDataPairs(data_ss,labels_np):\n",
    "    data_pairs=[]\n",
    "    data_pair_labels=[]\n",
    "    N=data_ss.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(i+1,N):\n",
    "            data_pairs.append((data_ss[i],data_ss[j]))\n",
    "            label=labels_np[i]==labels_np[j]\n",
    "            data_pair_labels.append(label)\n",
    "    data_pairs_np=np.array(data_pairs)\n",
    "    data_pair_labels_np=np.array(data_pair_labels)\n",
    "    return data_pairs_np, data_pair_labels_np\n",
    "data_pairs_np, data_pair_labels_np=buildDataPairs(data_ss,labels_np)\n",
    "print(data_pairs_np.shape)\n",
    "print(data_pair_labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "disciplinary-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (BatchNorm, Conv, Dense, Flatten, Dropout,\n",
    "                                   Relu, LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "informational-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some additional JAX and dataloader helpers\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "terminal-recommendation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#Test if JAX is using CPU or GPU\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "olympic-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "velvet-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "hidden=10\n",
    "dropout_rate=0.25\n",
    "def makeNet(num_classes,hidden,dropout_rate,mode=\"train\"):\n",
    "    init_fun, net = stax.serial(\n",
    "        Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        Relu,\n",
    "        #Dropout(dropout_rate,mode=mode),\n",
    "        #Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        #Relu,\n",
    "        Dropout(dropout_rate,mode=mode),\n",
    "        Dense(hidden),\n",
    "        Dense(num_classes))\n",
    "    return init_fun,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "frequent-invitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouput_shape= (-1, 2)\n"
     ]
    }
   ],
   "source": [
    "def initNets(data):\n",
    "    #buid net\n",
    "    init_fun, net=makeNet(num_classes,hidden,dropout_rate)\n",
    "    input_shape=(-1,)+ data.shape[1:]\n",
    "    output_shape, params = init_fun(key, input_shape)\n",
    "    #print(\"ouput_shape=\",output_shape)\n",
    "    _,netTest=makeNet(num_classes,hidden,dropout_rate,mode='test')  \n",
    "    #buid optimizer\n",
    "    step_size = 1e-4\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "    opt_state = opt_init(params)\n",
    "    return net,netTest,opt_state,get_params,opt_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "challenging-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k \"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)\n",
    "\n",
    "def loss(params, data, targets,key):\n",
    "    preds = net(params, data,rng=key)\n",
    "    return -np.sum(preds * targets)\n",
    "\n",
    "def predict(params,data,key):\n",
    "    preds=netTest(params,data,rng=key)\n",
    "    return np.exp(preds)\n",
    "\n",
    "def accuracy(p,targets):\n",
    "    target_class    = np.argmax(targets, axis=1)\n",
    "    predicted_class = np.argmax(p      , axis=1)\n",
    "    acc_total       = np.sum(predicted_class == target_class)\n",
    "    return acc_total/p.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "opposite-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1e-3\n",
    "opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "opt_state = opt_init(params)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "extensive-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state,key):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y,key)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "square-economics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "labels_onehot=one_hot(labels_np,num_classes)\n",
    "print(labels_onehot.shape)\n",
    "def run_training_loop(data_ss,labels_onehot,num_epochs, opt_state,verbose=False):\n",
    "    \"\"\" Implements a learning loop over epochs. \"\"\"\n",
    "    # Get the initial set of parameters\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    # Loop over the training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        params, opt_state, loss = update(params, data_ss, labels_onehot, opt_state,key)\n",
    "        epoch_time = time.time() - start_time\n",
    "        if verbose: print(\"Epoch {} | T: {:0.2f} | loss: {:0.3f} \".format(epoch+1, epoch_time,\n",
    "                                                                    loss))\n",
    "    return loss,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "narrative-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.281156\n"
     ]
    }
   ],
   "source": [
    "l,params=run_training_loop(data_ss,labels_onehot,2000,opt_state,False)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "flexible-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numpy_delete(x, idx):\n",
    "    \"\"\"\n",
    "    Gets the subarray from `x` where data from index `idx` on the first axis is removed.\n",
    "    \"\"\"\n",
    "    # NB: numpy.delete is not yet available in JAX\n",
    "    mask = np.arange(x.shape[0] - 1) < idx\n",
    "    return np.where(mask.reshape((-1,) + (1,) * (x.ndim - 1)), x[:-1], x[1:])\n",
    "def allButOne(x,y,i):\n",
    "    global key\n",
    "    oneX=x[i:i+1] #this return a (1,N) shape vs x[i] gives (N,) shape\n",
    "    oneY=y[i:i+1]\n",
    "    allXBut=_numpy_delete(x,i)\n",
    "    allYBut=_numpy_delete(y,i)\n",
    "    rng,key=random.split(key)\n",
    "    idxs=allXBut.shape[0]\n",
    "    suffleIdx=random.permutation(rng,idxs)\n",
    "    allXBut=allXBut[suffleIdx]\n",
    "    allYBut=allYBut[suffleIdx]\n",
    "    return allXBut,allYBut,oneX,oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "public-scheduling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 68)\n",
      "(49, 2)\n",
      "(1, 68)\n",
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.000, 1.000]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allXBut,allYBut,oneX,oneY=allButOne(data_ss,labels_onehot,1)\n",
    "print(allXBut.shape)\n",
    "print(allYBut.shape)\n",
    "print(oneX.shape)\n",
    "print(oneY.shape)\n",
    "oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 [[0.103 0.897]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=15.145\n",
      "i= 1 [[0.006 0.994]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=19.121\n",
      "i= 2 [[0.005 0.995]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=14.487\n",
      "i= 3 [[0.994 0.006]] [[0.000 1.000]] acc=0.000 accMean=0.750 loss=8.699\n",
      "i= 4 [[0.270 0.730]] [[0.000 1.000]] acc=1.000 accMean=0.800 loss=12.028\n",
      "i= 5 [[0.270 0.730]] [[0.000 1.000]] acc=1.000 accMean=0.833 loss=13.367\n",
      "i= 6 [[0.018 0.982]] [[0.000 1.000]] acc=1.000 accMean=0.857 loss=10.299\n",
      "i= 7 [[1.000 0.000]] [[0.000 1.000]] acc=0.000 accMean=0.750 loss=12.949\n",
      "i= 8 [[0.153 0.847]] [[0.000 1.000]] acc=1.000 accMean=0.778 loss=10.225\n",
      "i= 9 [[0.029 0.971]] [[0.000 1.000]] acc=1.000 accMean=0.800 loss=15.276\n",
      "i= 10 [[0.065 0.935]] [[1.000 0.000]] acc=0.000 accMean=0.727 loss=11.791\n",
      "i= 11 [[0.125 0.875]] [[1.000 0.000]] acc=0.000 accMean=0.667 loss=17.323\n",
      "i= 12 [[0.000 1.000]] [[1.000 0.000]] acc=0.000 accMean=0.615 loss=11.457\n",
      "i= 13 [[0.565 0.435]] [[1.000 0.000]] acc=1.000 accMean=0.643 loss=13.496\n",
      "i= 14 [[0.764 0.236]] [[1.000 0.000]] acc=1.000 accMean=0.667 loss=14.884\n",
      "i= 15 [[0.001 0.999]] [[1.000 0.000]] acc=0.000 accMean=0.625 loss=11.247\n",
      "i= 16 [[0.837 0.163]] [[1.000 0.000]] acc=1.000 accMean=0.647 loss=11.457\n",
      "i= 17 [[0.045 0.955]] [[1.000 0.000]] acc=0.000 accMean=0.611 loss=12.217\n",
      "i= 18 [[0.000 1.000]] [[1.000 0.000]] acc=0.000 accMean=0.579 loss=6.502\n",
      "i= 19 [[0.369 0.631]] [[1.000 0.000]] acc=0.000 accMean=0.550 loss=10.431\n",
      "i= 20 [[0.902 0.098]] [[0.000 1.000]] acc=0.000 accMean=0.524 loss=13.201\n",
      "i= 21 [[0.950 0.050]] [[0.000 1.000]] acc=0.000 accMean=0.500 loss=13.761\n",
      "i= 22 [[0.011 0.989]] [[0.000 1.000]] acc=1.000 accMean=0.522 loss=13.460\n",
      "i= 23 [[0.000 1.000]] [[0.000 1.000]] acc=1.000 accMean=0.542 loss=12.891\n",
      "i= 24 [[0.245 0.755]] [[0.000 1.000]] acc=1.000 accMean=0.560 loss=13.201\n",
      "i= 25 [[0.875 0.125]] [[0.000 1.000]] acc=0.000 accMean=0.538 loss=12.217\n",
      "i= 26 [[0.024 0.976]] [[0.000 1.000]] acc=1.000 accMean=0.556 loss=16.552\n",
      "i= 27 [[0.051 0.949]] [[0.000 1.000]] acc=1.000 accMean=0.571 loss=16.771\n",
      "i= 28 [[0.000 1.000]] [[0.000 1.000]] acc=1.000 accMean=0.586 loss=14.860\n"
     ]
    }
   ],
   "source": [
    "accT=0\n",
    "for i in range(data_ss.shape[0]):\n",
    "    allXBut,allYBut,oneX,oneY=allButOne(data_ss,labels_onehot,i)\n",
    "    loss,params=run_training_loop(allXBut,allYBut,20000,opt_state)\n",
    "    p=predict(params,oneX,key)\n",
    "    acc=accuracy(p,oneY)\n",
    "    accT+=acc\n",
    "    print(\"i=\",i,p,oneY,\"acc={0:0.3f} accMean={1:0.3f} loss={2:0.3f}\".format(acc,accT/(i+1),loss))\n",
    "print(\"accMean={0:0.3f}\".format(accT/(data_ss.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-romantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-trustee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-manchester",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
