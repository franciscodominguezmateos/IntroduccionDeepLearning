{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "driven-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Francisco Dominguez Mateos\n",
    "# 25/08/2021\n",
    "# Voice Stress detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "unlike-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "#np.set_printoptions(precision=3)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "trained-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base=\"/home/francisco/datasets/datasets/sound/voice/stress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "drawn-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return 1.0\n",
    "    if s==\"FALSE\":\n",
    "        return 0.0\n",
    "    if s==\"PC\":\n",
    "        return 2.0\n",
    "def isRightLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return True\n",
    "    if s==\"FALSE\":\n",
    "        return True\n",
    "    if s==\"PC\":\n",
    "        return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "photographic-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Males.csv\n",
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Females.csv\n",
      "(50, 68)\n",
      "[[126.278 0.014 0.029 ... 15.681 0.870 0.012]\n",
      " [142.901 0.005 0.019 ... 10.834 0.936 0.008]\n",
      " [117.189 0.005 0.014 ... 11.765 0.967 0.006]\n",
      " ...\n",
      " [192.269 0.008 0.022 ... 10.600 0.928 0.007]\n",
      " [167.700 0.005 0.025 ... 9.564 0.933 0.009]\n",
      " [206.086 0.007 0.013 ... 9.851 0.922 0.046]]\n",
      "(50,)\n",
      "[1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "file_txt=path_base+\"/*.csv\"\n",
    "for filepath in glob.glob(file_txt):\n",
    "    print(\"Processing file: {}\".format(filepath)) \n",
    "    with open(filepath) as fp:  \n",
    "        line = fp.readline()\n",
    "        head_list=line.split(\";\")\n",
    "        #for i,head in enumerate(head_list):\n",
    "        #    print(i,head)\n",
    "        cnt = 1\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            data_row=[]\n",
    "            line_list=line.split(\";\")\n",
    "            #print(\"Line {}: {} {} {}\".format(cnt, line_list[0], line_list[1], line_list[2]))\n",
    "            line = fp.readline()\n",
    "            cnt += 1\n",
    "            if not isRightLabel(line_list[0]):\n",
    "                continue\n",
    "            for i,datum in enumerate(line_list):\n",
    "                #print(i,head_list[i],\"=\",datum)\n",
    "                if i>1:\n",
    "                    data_row.append(float(datum))\n",
    "                if i==0:\n",
    "                    labels.append(getLabel(datum))\n",
    "            data.append(data_row)\n",
    "data_np=np.array(data)\n",
    "labels_np=np.array(labels)\n",
    "print(data_np.shape)\n",
    "print(data_np)\n",
    "print(labels_np.shape)\n",
    "print(labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sublime-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "greenhouse-certificate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 68)\n",
      "[[-0.692 1.335 0.942 ... 1.056 -1.550 -0.524]\n",
      " [-0.309 -0.907 -0.100 ... -0.261 0.011 -0.808]\n",
      " [-0.901 -0.907 -0.621 ... -0.008 0.744 -0.950]\n",
      " ...\n",
      " [0.826 -0.159 0.213 ... -0.325 -0.178 -0.879]\n",
      " [0.261 -0.907 0.525 ... -0.606 -0.060 -0.737]\n",
      " [1.144 -0.409 -0.725 ... -0.528 -0.320 1.895]]\n"
     ]
    }
   ],
   "source": [
    "ss=StandardScaler()\n",
    "data_ss=ss.fit_transform(data_np)\n",
    "\n",
    "print(data_ss.shape)\n",
    "print(data_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "threatened-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "steady-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7)\n"
     ]
    }
   ],
   "source": [
    "#pca=PCA(7,whiten=True)\n",
    "#data_ss=pca.fit_transform(data_np)\n",
    "#print(data_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "crude-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bibliographic-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "random_state = 0\n",
    "X=data_ss\n",
    "y=labels_np\n",
    "# Reduce dimension to 2 with NeighborhoodComponentAnalysis\n",
    "nca =NeighborhoodComponentsAnalysis(n_components=2,random_state=random_state)\n",
    "data_ss=nca.fit(X, y).transform(X)\n",
    "print(data_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "directed-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (BatchNorm, Conv, Dense, Flatten, Dropout,\n",
    "                                   Relu, LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bibliographic-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some additional JAX and dataloader helpers\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "classical-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "#Test if JAX is using CPU or GPU\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "invalid-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "outdoor-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "hidden=10\n",
    "dropout_rate=0.5\n",
    "def makeNet(num_classes,hidden,dropout_rate,mode=\"train\"):\n",
    "    init_fun, net = stax.serial(\n",
    "        Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        Relu,\n",
    "        #Dropout(dropout_rate,mode=mode),\n",
    "        #Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        #Relu,\n",
    "        #Dropout(dropout_rate,mode=mode),\n",
    "        #Dense(hidden),\n",
    "        Dense(num_classes),\n",
    "        LogSoftmax)\n",
    "    return init_fun,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bulgarian-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initNets(data):\n",
    "    #buid net\n",
    "    init_fun, net=makeNet(num_classes,hidden,dropout_rate)\n",
    "    input_shape=(-1,)+ data.shape[1:]\n",
    "    output_shape, params = init_fun(key, input_shape)\n",
    "    #print(\"ouput_shape=\",output_shape)\n",
    "    _,netTest=makeNet(num_classes,hidden,dropout_rate,mode='test')  \n",
    "    #buid optimizer\n",
    "    step_size = 1e-4\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "    opt_state = opt_init(params)\n",
    "    return net,netTest,opt_state,get_params,opt_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "brave-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "net,netTest,opt_state,get_params,opt_update=initNets(data_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "other-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_flatten\n",
    "\n",
    "def l2_squared(pytree):\n",
    "  leaves, _ = tree_flatten(pytree)\n",
    "  return sum(np.vdot(x, x) for x in leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dramatic-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k \"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)\n",
    "\n",
    "def loss(params, data, targets,key):\n",
    "    preds = net(params, data,rng=key)\n",
    "    return -np.sum(preds * targets)+l2_squared(params)\n",
    "\n",
    "def predict(params,data,key):\n",
    "    preds=netTest(params,data,rng=key)\n",
    "    return np.exp(preds)\n",
    "\n",
    "def accuracy(p,targets):\n",
    "    target_class    = np.argmax(targets, axis=1)\n",
    "    predicted_class = np.argmax(p      , axis=1)\n",
    "    acc_total       = np.sum(predicted_class == target_class)\n",
    "    return acc_total/p.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ceramic-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state,key):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y,key)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "recent-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "labels_onehot=one_hot(labels_np,num_classes)\n",
    "print(labels_onehot.shape)\n",
    "def run_training_loop(data_ss,labels_onehot,num_epochs, opt_state,verbose=False):\n",
    "    \"\"\" Implements a learning loop over epochs. \"\"\"\n",
    "    # Get the initial set of parameters\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    # Loop over the training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        params, opt_state, loss = update(params, data_ss, labels_onehot, opt_state,key)\n",
    "        epoch_time = time.time() - start_time\n",
    "        if verbose: print(\"Epoch {} | T: {:0.2f} | loss: {:0.3f} \".format(epoch+1, epoch_time,\n",
    "                                                                    loss))\n",
    "    return loss,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "final-evolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.652897\n"
     ]
    }
   ],
   "source": [
    "net,netTest,opt_state,get_params,opt_update=initNets(data_ss)\n",
    "l,params=run_training_loop(data_ss,labels_onehot,2000,opt_state,False)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "transparent-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numpy_delete(x, idx):\n",
    "    \"\"\"\n",
    "    Gets the subarray from `x` where data from index `idx` on the first axis is removed.\n",
    "    \"\"\"\n",
    "    # NB: numpy.delete is not yet available in JAX\n",
    "    mask = np.arange(x.shape[0] - 1) < idx\n",
    "    return np.where(mask.reshape((-1,) + (1,) * (x.ndim - 1)), x[:-1], x[1:])\n",
    "def allButOne(x,y,i):\n",
    "    global key\n",
    "    oneX=x[i:i+1] #this return a (1,N) shape vs x[i] gives (N,) shape\n",
    "    oneY=y[i:i+1]\n",
    "    allXBut=_numpy_delete(x,i)\n",
    "    allYBut=_numpy_delete(y,i)\n",
    "    rng,key=random.split(key)\n",
    "    idxs=allXBut.shape[0]\n",
    "    suffleIdx=random.permutation(rng,idxs)\n",
    "    allXBut=allXBut[suffleIdx]\n",
    "    allYBut=allYBut[suffleIdx]\n",
    "    return allXBut,allYBut,oneX,oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "detected-deputy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 2)\n",
      "(49, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.000, 1.000]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allXBut,allYBut,oneX,oneY=allButOne(data_ss,labels_onehot,1)\n",
    "print(allXBut.shape)\n",
    "print(allYBut.shape)\n",
    "print(oneX.shape)\n",
    "print(oneY.shape)\n",
    "oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "plain-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLeaveOneOut(data,labels_onehot,epochs=2000,verbose=True):\n",
    "    accT=0\n",
    "    for i in range(data_ss.shape[0]):\n",
    "        allXBut,allYBut,oneX,oneY=allButOne(data,labels_onehot,i)\n",
    "        loss,params=run_training_loop(allXBut,allYBut,epochs,opt_state)\n",
    "        p=predict(params,oneX,key)\n",
    "        acc=accuracy(p,oneY)\n",
    "        accT+=acc\n",
    "        if verbose:\n",
    "            print(\"i=\",i,p,oneY,\"acc={0:0.3f} accMean={1:0.3f} loss={2:0.3f}\".format(acc,accT/(i+1),loss))\n",
    "    return accT/(data_ss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "engaged-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 [[0.594 0.406]] [[0.000 1.000]] acc=0.000 accMean=0.000 loss=31.094\n",
      "i= 1 [[0.304 0.696]] [[0.000 1.000]] acc=1.000 accMean=0.500 loss=31.504\n",
      "i= 2 [[0.649 0.351]] [[0.000 1.000]] acc=0.000 accMean=0.333 loss=30.762\n",
      "i= 3 [[0.596 0.404]] [[0.000 1.000]] acc=0.000 accMean=0.250 loss=30.946\n",
      "i= 4 [[0.852 0.148]] [[0.000 1.000]] acc=0.000 accMean=0.200 loss=30.065\n",
      "i= 5 [[0.557 0.443]] [[0.000 1.000]] acc=0.000 accMean=0.167 loss=31.259\n",
      "i= 6 [[0.476 0.524]] [[0.000 1.000]] acc=1.000 accMean=0.286 loss=31.309\n",
      "i= 7 [[0.146 0.854]] [[0.000 1.000]] acc=1.000 accMean=0.375 loss=31.659\n",
      "i= 8 [[0.417 0.583]] [[0.000 1.000]] acc=1.000 accMean=0.444 loss=31.410\n",
      "i= 9 [[0.090 0.910]] [[0.000 1.000]] acc=1.000 accMean=0.500 loss=31.709\n",
      "i= 10 [[0.745 0.255]] [[1.000 0.000]] acc=1.000 accMean=0.545 loss=31.410\n",
      "i= 11 [[0.648 0.352]] [[1.000 0.000]] acc=1.000 accMean=0.583 loss=31.361\n",
      "i= 12 [[0.716 0.284]] [[1.000 0.000]] acc=1.000 accMean=0.615 loss=31.344\n",
      "i= 13 [[0.558 0.442]] [[1.000 0.000]] acc=1.000 accMean=0.643 loss=31.205\n",
      "i= 14 [[0.687 0.313]] [[1.000 0.000]] acc=1.000 accMean=0.667 loss=31.324\n",
      "i= 15 [[0.472 0.528]] [[1.000 0.000]] acc=0.000 accMean=0.625 loss=31.254\n",
      "i= 16 [[0.741 0.259]] [[1.000 0.000]] acc=1.000 accMean=0.647 loss=31.257\n",
      "i= 17 [[0.604 0.396]] [[1.000 0.000]] acc=1.000 accMean=0.667 loss=31.357\n",
      "i= 18 [[0.419 0.581]] [[1.000 0.000]] acc=0.000 accMean=0.632 loss=31.182\n",
      "i= 19 [[0.555 0.445]] [[1.000 0.000]] acc=1.000 accMean=0.650 loss=31.268\n",
      "i= 20 [[0.529 0.471]] [[0.000 1.000]] acc=0.000 accMean=0.619 loss=31.016\n",
      "i= 21 [[0.373 0.627]] [[0.000 1.000]] acc=1.000 accMean=0.636 loss=31.317\n",
      "i= 22 [[0.454 0.546]] [[0.000 1.000]] acc=1.000 accMean=0.652 loss=31.175\n",
      "i= 23 [[0.426 0.574]] [[0.000 1.000]] acc=1.000 accMean=0.667 loss=31.383\n",
      "i= 24 [[0.388 0.612]] [[0.000 1.000]] acc=1.000 accMean=0.680 loss=31.343\n",
      "i= 25 [[0.430 0.570]] [[0.000 1.000]] acc=1.000 accMean=0.692 loss=31.167\n",
      "i= 26 [[0.079 0.921]] [[0.000 1.000]] acc=1.000 accMean=0.704 loss=31.604\n",
      "i= 27 [[0.520 0.480]] [[0.000 1.000]] acc=0.000 accMean=0.679 loss=31.050\n",
      "i= 28 [[0.497 0.503]] [[0.000 1.000]] acc=1.000 accMean=0.690 loss=31.095\n",
      "i= 29 [[0.513 0.487]] [[0.000 1.000]] acc=0.000 accMean=0.667 loss=31.045\n",
      "i= 30 [[0.519 0.481]] [[0.000 1.000]] acc=0.000 accMean=0.645 loss=31.030\n",
      "i= 31 [[0.369 0.631]] [[0.000 1.000]] acc=1.000 accMean=0.656 loss=31.329\n",
      "i= 32 [[0.516 0.484]] [[0.000 1.000]] acc=0.000 accMean=0.636 loss=31.062\n",
      "i= 33 [[0.067 0.933]] [[0.000 1.000]] acc=1.000 accMean=0.647 loss=31.611\n",
      "i= 34 [[0.420 0.580]] [[0.000 1.000]] acc=1.000 accMean=0.657 loss=31.197\n",
      "i= 35 [[0.638 0.362]] [[1.000 0.000]] acc=1.000 accMean=0.667 loss=31.387\n",
      "i= 36 [[0.322 0.678]] [[1.000 0.000]] acc=0.000 accMean=0.649 loss=30.926\n",
      "i= 37 [[0.437 0.563]] [[1.000 0.000]] acc=0.000 accMean=0.632 loss=30.995\n",
      "i= 38 [[0.479 0.521]] [[1.000 0.000]] acc=0.000 accMean=0.615 loss=31.101\n",
      "i= 39 [[0.523 0.477]] [[1.000 0.000]] acc=1.000 accMean=0.625 loss=31.340\n",
      "i= 40 [[0.623 0.377]] [[1.000 0.000]] acc=1.000 accMean=0.634 loss=31.347\n",
      "i= 41 [[0.611 0.389]] [[1.000 0.000]] acc=1.000 accMean=0.643 loss=31.325\n",
      "i= 42 [[0.578 0.422]] [[1.000 0.000]] acc=1.000 accMean=0.651 loss=31.324\n",
      "i= 43 [[0.459 0.541]] [[1.000 0.000]] acc=0.000 accMean=0.636 loss=31.038\n",
      "i= 44 [[0.599 0.401]] [[1.000 0.000]] acc=1.000 accMean=0.644 loss=31.317\n",
      "i= 45 [[0.353 0.647]] [[1.000 0.000]] acc=0.000 accMean=0.630 loss=31.303\n",
      "i= 46 [[0.396 0.604]] [[1.000 0.000]] acc=0.000 accMean=0.617 loss=31.013\n",
      "i= 47 [[0.391 0.609]] [[1.000 0.000]] acc=0.000 accMean=0.604 loss=30.982\n",
      "i= 48 [[0.642 0.358]] [[1.000 0.000]] acc=1.000 accMean=0.612 loss=31.341\n",
      "i= 49 [[0.406 0.594]] [[1.000 0.000]] acc=0.000 accMean=0.600 loss=31.030\n",
      "accMean=0.600\n"
     ]
    }
   ],
   "source": [
    "accMean=runLeaveOneOut(data_ss,labels_onehot,epochs=10000)\n",
    "print(\"accMean={0:0.3f}\".format(accMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "violent-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=1 accMean=0.440\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=2 accMean=0.440\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=3 accMean=0.620\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=4 accMean=0.540\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=5 accMean=0.600\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=6 accMean=0.620\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=7 accMean=0.480\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=8 accMean=0.400\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=9 accMean=0.700\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=10 accMean=0.500\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=11 accMean=0.540\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=12 accMean=0.600\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=13 accMean=0.580\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=14 accMean=0.600\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=15 accMean=0.540\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=16 accMean=0.520\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=17 accMean=0.440\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=18 accMean=0.600\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=19 accMean=0.480\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=20 accMean=0.600\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=21 accMean=0.520\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=22 accMean=0.540\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=23 accMean=0.560\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=24 accMean=0.560\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=25 accMean=0.540\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=26 accMean=0.540\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=27 accMean=0.560\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=28 accMean=0.480\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=29 accMean=0.560\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=30 accMean=0.640\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=31 accMean=0.520\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=32 accMean=0.460\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=33 accMean=0.600\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=34 accMean=0.540\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=35 accMean=0.500\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=36 accMean=0.580\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=37 accMean=0.360\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=38 accMean=0.600\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=39 accMean=0.560\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=40 accMean=0.520\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=41 accMean=0.500\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=42 accMean=0.580\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=43 accMean=0.520\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=44 accMean=0.500\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=45 accMean=0.560\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=46 accMean=0.560\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=47 accMean=0.440\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=48 accMean=0.360\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 2)\n",
      "i=49 accMean=0.480\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,data_np.shape[0]):\n",
    "    #pca=PCA(i,whiten=True)\n",
    "    #data_ss=pca.fit_transform(data_np)\n",
    "    nca =NeighborhoodComponentsAnalysis(n_components=2,random_state=random_state)\n",
    "    data_ss=nca.fit(X, y).transform(X)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(data_ss.shape)\n",
    "    net,netTest,opt_state,get_params,opt_update=initNets(data_ss)\n",
    "    accMean=runLeaveOneOut(data_ss,labels_onehot,epochs=10000,verbose=False)\n",
    "    print(\"i={0:} accMean={1:0.3f}\".format(i,accMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-affect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-differential",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
