{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nervous-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Francisco Dominguez Mateos\n",
    "# 25/08/2021\n",
    "# Voice Stress detection PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "architectural-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "#np.set_printoptions(precision=3)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "marked-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base=\"/home/francisco/datasets/datasets/sound/voice/stress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extreme-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return 1.0\n",
    "    if s==\"FALSE\":\n",
    "        return 0.0\n",
    "    if s==\"PC\":\n",
    "        return 2.0\n",
    "def isRightLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return True\n",
    "    if s==\"FALSE\":\n",
    "        return True\n",
    "    if s==\"PC\":\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "registered-priest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Males.csv\n",
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Females.csv\n",
      "(76, 68)\n",
      "[[126.278 0.014 0.029 ... 15.681 0.870 0.012]\n",
      " [142.901 0.005 0.019 ... 10.834 0.936 0.008]\n",
      " [117.189 0.005 0.014 ... 11.765 0.967 0.006]\n",
      " ...\n",
      " [231.855 0.016 0.014 ... 10.118 0.933 0.018]\n",
      " [202.053 0.020 0.024 ... 15.960 0.903 0.013]\n",
      " [235.090 0.014 0.023 ... 8.176 0.936 0.291]]\n",
      "(76,)\n",
      "[1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 2.000 2.000 2.000 2.000\n",
      " 2.000 2.000 2.000 2.000 2.000 2.000 2.000 2.000 2.000 2.000 2.000 2.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 2.000 2.000 2.000 2.000 2.000 2.000\n",
      " 2.000 2.000 2.000 2.000]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "file_txt=path_base+\"/*.csv\"\n",
    "for filepath in glob.glob(file_txt):\n",
    "    print(\"Processing file: {}\".format(filepath)) \n",
    "    with open(filepath) as fp:  \n",
    "        line = fp.readline()\n",
    "        head_list=line.split(\";\")\n",
    "        #for i,head in enumerate(head_list):\n",
    "        #    print(i,head)\n",
    "        cnt = 1\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            data_row=[]\n",
    "            line_list=line.split(\";\")\n",
    "            #print(\"Line {}: {} {} {}\".format(cnt, line_list[0], line_list[1], line_list[2]))\n",
    "            line = fp.readline()\n",
    "            cnt += 1\n",
    "            if not isRightLabel(line_list[0]):\n",
    "                continue\n",
    "            for i,datum in enumerate(line_list):\n",
    "                #print(i,head_list[i],\"=\",datum)\n",
    "                if i>1:\n",
    "                    data_row.append(float(datum))\n",
    "                if i==0:\n",
    "                    labels.append(getLabel(datum))\n",
    "            data.append(data_row)\n",
    "data_np=np.array(data)\n",
    "labels_np=np.array(labels)\n",
    "print(data_np.shape)\n",
    "print(data_np)\n",
    "print(labels_np.shape)\n",
    "print(labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "potential-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "victorian-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 68)\n",
      "[[-0.429 -0.118 -0.110 ... 0.630 -1.390 -0.450]\n",
      " [-0.210 -0.254 -0.165 ... -0.263 -0.010 -0.545]\n",
      " [-0.548 -0.254 -0.193 ... -0.092 0.638 -0.593]\n",
      " ...\n",
      " [0.959 -0.087 -0.193 ... -0.395 -0.073 -0.308]\n",
      " [0.568 -0.027 -0.138 ... 0.682 -0.700 -0.426]\n",
      " [1.002 -0.118 -0.143 ... -0.754 -0.010 6.185]]\n"
     ]
    }
   ],
   "source": [
    "ss=StandardScaler()\n",
    "data_ss=ss.fit_transform(data_np)\n",
    "\n",
    "print(data_ss.shape)\n",
    "print(data_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adjusted-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k \"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aquatic-vancouver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "num_classes=int(np.max(labels_np)+1)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "united-processor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 3)\n"
     ]
    }
   ],
   "source": [
    "labels_onehot=one_hot(labels_np,num_classes)\n",
    "print(labels_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "drawn-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (BatchNorm, Conv, Dense, Flatten, Dropout,\n",
    "                                   Relu, LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "crucial-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some additional JAX and dataloader helpers\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "distant-share",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "#Test if JAX is using CPU or GPU\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accurate-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "female-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden=25\n",
    "dropout_rate=0.50\n",
    "def makeNet(num_classes,hidden,dropout_rate,mode=\"train\"):\n",
    "    init_fun, net = stax.serial(\n",
    "        Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        Relu,\n",
    "        #Dropout(dropout_rate,mode=mode),\n",
    "        #Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        #Relu,\n",
    "        Dropout(dropout_rate,mode=mode),\n",
    "        Dense(num_classes),\n",
    "        Dense(num_classes),\n",
    "        LogSoftmax)\n",
    "    return init_fun,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "small-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape= (-1, 68)\n",
      "ouput_shape= (-1, 3)\n"
     ]
    }
   ],
   "source": [
    "init_fun, net=makeNet(num_classes,hidden,dropout_rate)\n",
    "input_shape=(-1,)+ data_ss.shape[1:]\n",
    "print(\"input_shape=\",input_shape)\n",
    "output_shape, params = init_fun(key, input_shape)\n",
    "print(\"ouput_shape=\",output_shape)\n",
    "_,netTest=makeNet(num_classes,hidden,dropout_rate,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "loved-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, data, targets,key):\n",
    "    preds = net(params, data,rng=key)\n",
    "    return -np.sum(preds * targets)\n",
    "\n",
    "def predict(params,data,key):\n",
    "    preds=netTest(params,data,rng=key)\n",
    "    return np.exp(preds)\n",
    "\n",
    "def accuracy(p,targets):\n",
    "    target_class    = np.argmax(targets, axis=1)\n",
    "    predicted_class = np.argmax(p      , axis=1)\n",
    "    acc_total       = np.sum(predicted_class == target_class)\n",
    "    return acc_total/p.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "checked-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1e-3\n",
    "opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "opt_state = opt_init(params)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "attended-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state,key):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y,key)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "public-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_loop(data_ss,labels_onehot,num_epochs, opt_state,verbose=False):\n",
    "    \"\"\" Implements a learning loop over epochs. \"\"\"\n",
    "    # Get the initial set of parameters\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    # Loop over the training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        params, opt_state, loss = update(params, data_ss, labels_onehot, opt_state,key)\n",
    "        epoch_time = time.time() - start_time\n",
    "        if verbose: print(\"Epoch {} | T: {:0.2f} | loss: {:0.3f} \".format(epoch+1, epoch_time,\n",
    "                                                                    loss))\n",
    "    return loss,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "everyday-litigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4337315\n"
     ]
    }
   ],
   "source": [
    "l,params=run_training_loop(data_ss,labels_onehot,2000,opt_state,False)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "prostate-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numpy_delete(x, idx):\n",
    "    \"\"\"\n",
    "    Gets the subarray from `x` where data from index `idx` on the first axis is removed.\n",
    "    \"\"\"\n",
    "    # NB: numpy.delete is not yet available in JAX\n",
    "    mask = np.arange(x.shape[0] - 1) < idx\n",
    "    return np.where(mask.reshape((-1,) + (1,) * (x.ndim - 1)), x[:-1], x[1:])\n",
    "def allButOne(x,y,i):\n",
    "    global key\n",
    "    oneX=x[i:i+1] #this return a (1,N) shape vs x[i] gives (N,) shape\n",
    "    oneY=y[i:i+1]\n",
    "    allXBut=_numpy_delete(x,i)\n",
    "    allYBut=_numpy_delete(y,i)\n",
    "    rng,key=random.split(key)\n",
    "    idxs=allXBut.shape[0]\n",
    "    suffleIdx=random.permutation(rng,idxs)\n",
    "    allXBut=allXBut[suffleIdx]\n",
    "    allYBut=allYBut[suffleIdx]\n",
    "    return allXBut,allYBut,oneX,oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "varied-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 68)\n",
      "(75, 3)\n",
      "(1, 68)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.000, 1.000, 0.000]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allXBut,allYBut,oneX,oneY=allButOne(data_ss,labels_onehot,1)\n",
    "print(allXBut.shape)\n",
    "print(allYBut.shape)\n",
    "print(oneX.shape)\n",
    "print(oneY.shape)\n",
    "oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "related-mistake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 [[1.000 0.000 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.000 loss=0.000\n",
      "i= 1 [[1.000 0.000 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.000 loss=0.000\n",
      "i= 2 [[0.994 0.006 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.000 loss=0.000\n",
      "i= 3 [[0.034 0.966 0.000]] [[0.000 1.000 0.000]] acc=1.000 accMean=0.250 loss=0.000\n",
      "i= 4 [[0.997 0.003 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.200 loss=0.000\n",
      "i= 5 [[0.000 0.000 1.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.167 loss=0.000\n",
      "i= 6 [[0.995 0.005 0.001]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.143 loss=0.000\n",
      "i= 7 [[0.000 0.000 1.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.125 loss=0.000\n",
      "i= 8 [[0.990 0.010 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.111 loss=0.000\n",
      "i= 9 [[0.000 0.001 0.998]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.100 loss=-0.000\n",
      "i= 10 [[0.410 0.589 0.001]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.091 loss=0.000\n",
      "i= 11 [[0.002 0.998 0.000]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.083 loss=0.000\n",
      "i= 12 [[0.000 0.003 0.997]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.077 loss=0.000\n",
      "i= 13 [[0.010 0.882 0.109]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.071 loss=0.000\n",
      "i= 14 [[0.348 0.028 0.624]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.067 loss=-0.000\n",
      "i= 15 [[0.029 0.971 0.000]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.062 loss=0.000\n",
      "i= 16 [[0.000 0.772 0.228]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.059 loss=0.000\n",
      "i= 17 [[0.096 0.901 0.004]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.056 loss=0.000\n",
      "i= 18 [[0.000 0.999 0.001]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.053 loss=0.000\n",
      "i= 19 [[0.446 0.001 0.553]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.050 loss=0.000\n",
      "i= 20 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.095 loss=0.000\n",
      "i= 21 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.136 loss=0.000\n",
      "i= 22 [[1.000 0.000 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.130 loss=0.000\n",
      "i= 23 [[0.154 0.846 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.125 loss=-0.000\n",
      "i= 24 [[0.032 0.005 0.963]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.160 loss=-0.000\n",
      "i= 25 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.192 loss=0.000\n",
      "i= 26 [[0.010 0.000 0.990]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.222 loss=0.000\n",
      "i= 27 [[0.884 0.110 0.007]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.214 loss=0.000\n",
      "i= 28 [[0.000 0.007 0.993]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.241 loss=0.000\n",
      "i= 29 [[0.069 0.009 0.922]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.267 loss=-0.000\n",
      "i= 30 [[0.738 0.262 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.258 loss=0.000\n",
      "i= 31 [[0.995 0.005 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.250 loss=0.000\n",
      "i= 32 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.273 loss=-0.000\n",
      "i= 33 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.294 loss=0.000\n",
      "i= 34 [[0.006 0.002 0.992]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.314 loss=0.000\n",
      "i= 35 [[0.743 0.000 0.257]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.306 loss=0.000\n",
      "i= 36 [[1.000 0.000 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.297 loss=0.000\n",
      "i= 37 [[1.000 0.000 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.289 loss=0.000\n",
      "i= 38 [[0.992 0.003 0.005]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.282 loss=0.000\n",
      "i= 39 [[0.570 0.383 0.048]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.275 loss=0.000\n",
      "i= 40 [[1.000 0.000 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.268 loss=0.000\n",
      "i= 41 [[0.818 0.000 0.182]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.262 loss=-0.000\n",
      "i= 42 [[0.982 0.018 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.256 loss=0.000\n",
      "i= 43 [[0.035 0.965 0.000]] [[0.000 1.000 0.000]] acc=1.000 accMean=0.273 loss=0.000\n",
      "i= 44 [[0.989 0.011 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.267 loss=0.000\n",
      "i= 45 [[1.000 0.000 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.261 loss=0.000\n",
      "i= 46 [[1.000 0.000 0.000]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.255 loss=0.000\n",
      "i= 47 [[0.250 0.750 0.000]] [[0.000 1.000 0.000]] acc=1.000 accMean=0.271 loss=1.386\n",
      "i= 48 [[0.005 0.042 0.954]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.265 loss=0.000\n",
      "i= 49 [[0.948 0.000 0.052]] [[0.000 1.000 0.000]] acc=0.000 accMean=0.260 loss=1.386\n",
      "i= 50 [[0.000 1.000 0.000]] [[0.000 1.000 0.000]] acc=1.000 accMean=0.275 loss=0.000\n",
      "i= 51 [[0.450 0.548 0.003]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.269 loss=0.000\n",
      "i= 52 [[0.958 0.006 0.036]] [[1.000 0.000 0.000]] acc=1.000 accMean=0.283 loss=0.000\n",
      "i= 53 [[0.621 0.051 0.329]] [[1.000 0.000 0.000]] acc=1.000 accMean=0.296 loss=0.000\n",
      "i= 54 [[0.000 0.959 0.041]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.291 loss=0.000\n",
      "i= 55 [[0.011 0.989 0.000]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.286 loss=0.000\n",
      "i= 56 [[0.998 0.002 0.000]] [[1.000 0.000 0.000]] acc=1.000 accMean=0.298 loss=0.000\n",
      "i= 57 [[0.000 1.000 0.000]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.293 loss=0.000\n",
      "i= 58 [[0.003 0.939 0.058]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.288 loss=-0.000\n",
      "i= 59 [[1.000 0.000 0.000]] [[1.000 0.000 0.000]] acc=1.000 accMean=0.300 loss=-0.000\n",
      "i= 60 [[0.166 0.834 0.000]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.295 loss=-0.000\n",
      "i= 61 [[0.000 0.004 0.996]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.290 loss=0.000\n",
      "i= 62 [[1.000 0.000 0.000]] [[1.000 0.000 0.000]] acc=1.000 accMean=0.302 loss=0.000\n",
      "i= 63 [[0.012 0.978 0.010]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.297 loss=1.386\n",
      "i= 64 [[0.254 0.744 0.002]] [[1.000 0.000 0.000]] acc=0.000 accMean=0.292 loss=-0.000\n",
      "i= 65 [[0.885 0.115 0.000]] [[1.000 0.000 0.000]] acc=1.000 accMean=0.303 loss=0.000\n",
      "i= 66 [[0.000 1.000 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.299 loss=-0.000\n",
      "i= 67 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.309 loss=0.000\n",
      "i= 68 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.319 loss=0.000\n",
      "i= 69 [[0.000 0.000 1.000]] [[0.000 0.000 1.000]] acc=1.000 accMean=0.329 loss=-0.000\n",
      "i= 70 [[0.999 0.000 0.001]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.324 loss=0.000\n",
      "i= 71 [[0.995 0.005 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.319 loss=0.000\n",
      "i= 72 [[1.000 0.000 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.315 loss=0.000\n",
      "i= 73 [[0.551 0.449 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.311 loss=0.000\n",
      "i= 74 [[0.000 1.000 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.307 loss=0.000\n",
      "i= 75 [[1.000 0.000 0.000]] [[0.000 0.000 1.000]] acc=0.000 accMean=0.303 loss=0.000\n",
      "accMean=0.303\n"
     ]
    }
   ],
   "source": [
    "accT=0\n",
    "for i in range(data_ss.shape[0]):\n",
    "    allXBut,allYBut,oneX,oneY=allButOne(data_ss,labels_onehot,i)\n",
    "    loss,params=run_training_loop(allXBut,allYBut,20000,opt_state)\n",
    "    p=predict(params,oneX,key)\n",
    "    acc=accuracy(p,oneY)\n",
    "    accT+=acc\n",
    "    print(\"i=\",i,p,oneY,\"acc={0:0.3f} accMean={1:0.3f} loss={2:0.3f}\".format(acc,accT/(i+1),loss))\n",
    "print(\"accMean={0:0.3f}\".format(accT/(data_ss.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-morris",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-learning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
