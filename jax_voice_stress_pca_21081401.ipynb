{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooked-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Francisco Dominguez Mateos\n",
    "# 25/08/2021\n",
    "# Voice Stress detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "#np.set_printoptions(precision=3)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structured-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base=\"/home/francisco/datasets/datasets/sound/voice/stress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mature-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return 1.0\n",
    "    if s==\"FALSE\":\n",
    "        return 0.0\n",
    "    if s==\"PC\":\n",
    "        return 2.0\n",
    "def isRightLabel(s):\n",
    "    if s==\"TRUE\":\n",
    "        return True\n",
    "    if s==\"FALSE\":\n",
    "        return True\n",
    "    if s==\"PC\":\n",
    "        return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "steady-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Males.csv\n",
      "Processing file: /home/francisco/datasets/datasets/sound/voice/stress/Set_Females.csv\n",
      "(50, 68)\n",
      "[[126.278 0.014 0.029 ... 15.681 0.870 0.012]\n",
      " [142.901 0.005 0.019 ... 10.834 0.936 0.008]\n",
      " [117.189 0.005 0.014 ... 11.765 0.967 0.006]\n",
      " ...\n",
      " [192.269 0.008 0.022 ... 10.600 0.928 0.007]\n",
      " [167.700 0.005 0.025 ... 9.564 0.933 0.009]\n",
      " [206.086 0.007 0.013 ... 9.851 0.922 0.046]]\n",
      "(50,)\n",
      "[1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000\n",
      " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "file_txt=path_base+\"/*.csv\"\n",
    "for filepath in glob.glob(file_txt):\n",
    "    print(\"Processing file: {}\".format(filepath)) \n",
    "    with open(filepath) as fp:  \n",
    "        line = fp.readline()\n",
    "        head_list=line.split(\";\")\n",
    "        #for i,head in enumerate(head_list):\n",
    "        #    print(i,head)\n",
    "        cnt = 1\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            data_row=[]\n",
    "            line_list=line.split(\";\")\n",
    "            #print(\"Line {}: {} {} {}\".format(cnt, line_list[0], line_list[1], line_list[2]))\n",
    "            line = fp.readline()\n",
    "            cnt += 1\n",
    "            if not isRightLabel(line_list[0]):\n",
    "                continue\n",
    "            for i,datum in enumerate(line_list):\n",
    "                #print(i,head_list[i],\"=\",datum)\n",
    "                if i>1:\n",
    "                    data_row.append(float(datum))\n",
    "                if i==0:\n",
    "                    labels.append(getLabel(datum))\n",
    "            data.append(data_row)\n",
    "data_np=np.array(data)\n",
    "labels_np=np.array(labels)\n",
    "print(data_np.shape)\n",
    "print(data_np)\n",
    "print(labels_np.shape)\n",
    "print(labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noticed-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "threaded-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 68)\n",
      "[[-0.692 1.335 0.942 ... 1.056 -1.550 -0.524]\n",
      " [-0.309 -0.907 -0.100 ... -0.261 0.011 -0.808]\n",
      " [-0.901 -0.907 -0.621 ... -0.008 0.744 -0.950]\n",
      " ...\n",
      " [0.826 -0.159 0.213 ... -0.325 -0.178 -0.879]\n",
      " [0.261 -0.907 0.525 ... -0.606 -0.060 -0.737]\n",
      " [1.144 -0.409 -0.725 ... -0.528 -0.320 1.895]]\n"
     ]
    }
   ],
   "source": [
    "ss=StandardScaler()\n",
    "data_ss=ss.fit_transform(data_np)\n",
    "\n",
    "print(data_ss.shape)\n",
    "print(data_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "activated-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "friendly-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7)\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(7,whiten=True)\n",
    "data_ss=pca.fit_transform(data_np)\n",
    "print(data_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "british-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (BatchNorm, Conv, Dense, Flatten, Dropout,\n",
    "                                   Relu, LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "falling-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some additional JAX and dataloader helpers\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "approximate-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "#Test if JAX is using CPU or GPU\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "relative-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "collect-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "hidden=10\n",
    "dropout_rate=0.5\n",
    "def makeNet(num_classes,hidden,dropout_rate,mode=\"train\"):\n",
    "    init_fun, net = stax.serial(\n",
    "        Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        Relu,\n",
    "        #Dropout(dropout_rate,mode=mode),\n",
    "        #Dense(hidden),\n",
    "        #BatchNorm(axis=0),\n",
    "        #Relu,\n",
    "        #Dropout(dropout_rate,mode=mode),\n",
    "        #Dense(hidden),\n",
    "        Dense(num_classes),\n",
    "        LogSoftmax)\n",
    "    return init_fun,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "included-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initNets(data):\n",
    "    #buid net\n",
    "    init_fun, net=makeNet(num_classes,hidden,dropout_rate)\n",
    "    input_shape=(-1,)+ data.shape[1:]\n",
    "    output_shape, params = init_fun(key, input_shape)\n",
    "    #print(\"ouput_shape=\",output_shape)\n",
    "    _,netTest=makeNet(num_classes,hidden,dropout_rate,mode='test')  \n",
    "    #buid optimizer\n",
    "    step_size = 1e-4\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "    opt_state = opt_init(params)\n",
    "    return net,netTest,opt_state,get_params,opt_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "happy-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "net,netTest,opt_state,get_params,opt_update=initNets(data_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "tracked-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_flatten\n",
    "\n",
    "def l2_squared(pytree):\n",
    "  leaves, _ = tree_flatten(pytree)\n",
    "  return sum(np.vdot(x, x) for x in leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "medical-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k \"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)\n",
    "\n",
    "def loss(params, data, targets,key):\n",
    "    preds = net(params, data,rng=key)\n",
    "    return -np.sum(preds * targets)+l2_squared(params)\n",
    "\n",
    "def predict(params,data,key):\n",
    "    preds=netTest(params,data,rng=key)\n",
    "    return np.exp(preds)\n",
    "\n",
    "def accuracy(p,targets):\n",
    "    target_class    = np.argmax(targets, axis=1)\n",
    "    predicted_class = np.argmax(p      , axis=1)\n",
    "    acc_total       = np.sum(predicted_class == target_class)\n",
    "    return acc_total/p.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "satisfied-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state,key):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y,key)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ranging-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "labels_onehot=one_hot(labels_np,num_classes)\n",
    "print(labels_onehot.shape)\n",
    "def run_training_loop(data_ss,labels_onehot,num_epochs, opt_state,verbose=False):\n",
    "    \"\"\" Implements a learning loop over epochs. \"\"\"\n",
    "    # Get the initial set of parameters\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    # Loop over the training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        params, opt_state, loss = update(params, data_ss, labels_onehot, opt_state,key)\n",
    "        epoch_time = time.time() - start_time\n",
    "        if verbose: print(\"Epoch {} | T: {:0.2f} | loss: {:0.3f} \".format(epoch+1, epoch_time,\n",
    "                                                                    loss))\n",
    "    return loss,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "nearby-matthew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.020134\n"
     ]
    }
   ],
   "source": [
    "net,netTest,opt_state,get_params,opt_update=initNets(data_ss)\n",
    "l,params=run_training_loop(data_ss,labels_onehot,2000,opt_state,False)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "powered-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numpy_delete(x, idx):\n",
    "    \"\"\"\n",
    "    Gets the subarray from `x` where data from index `idx` on the first axis is removed.\n",
    "    \"\"\"\n",
    "    # NB: numpy.delete is not yet available in JAX\n",
    "    mask = np.arange(x.shape[0] - 1) < idx\n",
    "    return np.where(mask.reshape((-1,) + (1,) * (x.ndim - 1)), x[:-1], x[1:])\n",
    "def allButOne(x,y,i):\n",
    "    global key\n",
    "    oneX=x[i:i+1] #this return a (1,N) shape vs x[i] gives (N,) shape\n",
    "    oneY=y[i:i+1]\n",
    "    allXBut=_numpy_delete(x,i)\n",
    "    allYBut=_numpy_delete(y,i)\n",
    "    rng,key=random.split(key)\n",
    "    idxs=allXBut.shape[0]\n",
    "    suffleIdx=random.permutation(rng,idxs)\n",
    "    allXBut=allXBut[suffleIdx]\n",
    "    allYBut=allYBut[suffleIdx]\n",
    "    return allXBut,allYBut,oneX,oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "great-transcription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 49)\n",
      "(49, 2)\n",
      "(1, 49)\n",
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.000, 1.000]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allXBut,allYBut,oneX,oneY=allButOne(data_ss,labels_onehot,1)\n",
    "print(allXBut.shape)\n",
    "print(allYBut.shape)\n",
    "print(oneX.shape)\n",
    "print(oneY.shape)\n",
    "oneY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "enclosed-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLeaveOneOut(data,labels_onehot,epochs=2000,verbose=True):\n",
    "    accT=0\n",
    "    for i in range(data_ss.shape[0]):\n",
    "        allXBut,allYBut,oneX,oneY=allButOne(data,labels_onehot,i)\n",
    "        loss,params=run_training_loop(allXBut,allYBut,epochs,opt_state)\n",
    "        p=predict(params,oneX,key)\n",
    "        acc=accuracy(p,oneY)\n",
    "        accT+=acc\n",
    "        if verbose:\n",
    "            print(\"i=\",i,p,oneY,\"acc={0:0.3f} accMean={1:0.3f} loss={2:0.3f}\".format(acc,accT/(i+1),loss))\n",
    "    return accT/(data_ss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "narrative-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 [[0.412 0.588]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=11.644\n",
      "i= 1 [[0.491 0.509]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=11.400\n",
      "i= 2 [[0.487 0.513]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=11.524\n",
      "i= 3 [[0.487 0.513]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=11.287\n",
      "i= 4 [[0.413 0.587]] [[0.000 1.000]] acc=1.000 accMean=1.000 loss=11.627\n",
      "i= 5 [[0.575 0.425]] [[0.000 1.000]] acc=0.000 accMean=0.833 loss=11.541\n",
      "i= 6 [[0.445 0.555]] [[0.000 1.000]] acc=1.000 accMean=0.857 loss=11.525\n",
      "i= 7 [[0.396 0.604]] [[0.000 1.000]] acc=1.000 accMean=0.875 loss=11.301\n",
      "i= 8 [[0.474 0.526]] [[0.000 1.000]] acc=1.000 accMean=0.889 loss=11.594\n",
      "i= 9 [[0.358 0.642]] [[0.000 1.000]] acc=1.000 accMean=0.900 loss=11.483\n",
      "i= 10 [[0.518 0.482]] [[1.000 0.000]] acc=1.000 accMean=0.909 loss=11.586\n",
      "i= 11 [[0.518 0.482]] [[1.000 0.000]] acc=1.000 accMean=0.917 loss=11.662\n",
      "i= 12 [[0.548 0.452]] [[1.000 0.000]] acc=1.000 accMean=0.923 loss=11.441\n",
      "i= 13 [[0.392 0.608]] [[1.000 0.000]] acc=0.000 accMean=0.857 loss=11.400\n",
      "i= 14 [[0.436 0.564]] [[1.000 0.000]] acc=0.000 accMean=0.800 loss=11.488\n",
      "i= 15 [[0.454 0.546]] [[1.000 0.000]] acc=0.000 accMean=0.750 loss=11.560\n",
      "i= 16 [[0.344 0.656]] [[1.000 0.000]] acc=0.000 accMean=0.706 loss=11.383\n",
      "i= 17 [[0.433 0.567]] [[1.000 0.000]] acc=0.000 accMean=0.667 loss=11.453\n",
      "i= 18 [[0.335 0.665]] [[1.000 0.000]] acc=0.000 accMean=0.632 loss=11.355\n",
      "i= 19 [[0.460 0.540]] [[1.000 0.000]] acc=0.000 accMean=0.600 loss=11.311\n",
      "i= 20 [[0.275 0.725]] [[0.000 1.000]] acc=1.000 accMean=0.619 loss=11.405\n",
      "i= 21 [[0.472 0.528]] [[0.000 1.000]] acc=1.000 accMean=0.636 loss=11.511\n",
      "i= 22 [[0.507 0.493]] [[0.000 1.000]] acc=0.000 accMean=0.609 loss=11.498\n",
      "i= 23 [[0.527 0.473]] [[0.000 1.000]] acc=0.000 accMean=0.583 loss=11.530\n",
      "i= 24 [[0.445 0.555]] [[0.000 1.000]] acc=1.000 accMean=0.600 loss=11.538\n",
      "i= 25 [[0.447 0.553]] [[0.000 1.000]] acc=1.000 accMean=0.615 loss=11.462\n",
      "i= 26 [[0.419 0.581]] [[0.000 1.000]] acc=1.000 accMean=0.630 loss=11.600\n",
      "i= 27 [[0.448 0.552]] [[0.000 1.000]] acc=1.000 accMean=0.643 loss=11.441\n",
      "i= 28 [[0.612 0.388]] [[0.000 1.000]] acc=0.000 accMean=0.621 loss=11.508\n",
      "i= 29 [[0.568 0.432]] [[0.000 1.000]] acc=0.000 accMean=0.600 loss=11.541\n",
      "i= 30 [[0.420 0.580]] [[0.000 1.000]] acc=1.000 accMean=0.613 loss=11.601\n",
      "i= 31 [[0.490 0.510]] [[0.000 1.000]] acc=1.000 accMean=0.625 loss=11.431\n",
      "i= 32 [[0.498 0.502]] [[0.000 1.000]] acc=1.000 accMean=0.636 loss=11.459\n",
      "i= 33 [[0.527 0.473]] [[0.000 1.000]] acc=0.000 accMean=0.618 loss=11.500\n",
      "i= 34 [[0.541 0.459]] [[0.000 1.000]] acc=0.000 accMean=0.600 loss=11.590\n",
      "i= 35 [[0.398 0.602]] [[1.000 0.000]] acc=0.000 accMean=0.583 loss=11.407\n",
      "i= 36 [[0.548 0.452]] [[1.000 0.000]] acc=1.000 accMean=0.595 loss=11.552\n",
      "i= 37 [[0.493 0.507]] [[1.000 0.000]] acc=0.000 accMean=0.579 loss=11.443\n",
      "i= 38 [[0.465 0.535]] [[1.000 0.000]] acc=0.000 accMean=0.564 loss=11.414\n",
      "i= 39 [[0.636 0.364]] [[1.000 0.000]] acc=1.000 accMean=0.575 loss=11.617\n",
      "i= 40 [[0.405 0.595]] [[1.000 0.000]] acc=0.000 accMean=0.561 loss=11.414\n",
      "i= 41 [[0.590 0.410]] [[1.000 0.000]] acc=1.000 accMean=0.571 loss=11.664\n",
      "i= 42 [[0.620 0.380]] [[1.000 0.000]] acc=1.000 accMean=0.581 loss=11.516\n",
      "i= 43 [[0.411 0.589]] [[1.000 0.000]] acc=0.000 accMean=0.568 loss=11.293\n",
      "i= 44 [[0.397 0.603]] [[1.000 0.000]] acc=0.000 accMean=0.556 loss=11.356\n",
      "i= 45 [[0.552 0.448]] [[1.000 0.000]] acc=1.000 accMean=0.565 loss=11.655\n",
      "i= 46 [[0.431 0.569]] [[1.000 0.000]] acc=0.000 accMean=0.553 loss=11.532\n",
      "i= 47 [[0.542 0.458]] [[1.000 0.000]] acc=1.000 accMean=0.562 loss=11.511\n",
      "i= 48 [[0.517 0.483]] [[1.000 0.000]] acc=1.000 accMean=0.571 loss=11.411\n",
      "i= 49 [[0.434 0.566]] [[1.000 0.000]] acc=0.000 accMean=0.560 loss=11.396\n",
      "accMean=0.560\n"
     ]
    }
   ],
   "source": [
    "accMean=runLeaveOneOut(data_ss,labels_onehot,epochs=10000)\n",
    "print(\"accMean={0:0.3f}\".format(accMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "polished-pepper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.918]\n",
      "(50, 1)\n",
      "i=1 accMean=0.040\n",
      "[0.918 0.076]\n",
      "(50, 2)\n",
      "i=2 accMean=0.220\n",
      "[0.918 0.076 0.005]\n",
      "(50, 3)\n",
      "i=3 accMean=0.440\n",
      "[0.918 0.076 0.005 0.001]\n",
      "(50, 4)\n",
      "i=4 accMean=0.360\n",
      "[0.918 0.076 0.005 0.001 0.000]\n",
      "(50, 5)\n",
      "i=5 accMean=0.340\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000]\n",
      "(50, 6)\n",
      "i=6 accMean=0.460\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000]\n",
      "(50, 7)\n",
      "i=7 accMean=0.380\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000]\n",
      "(50, 8)\n",
      "i=8 accMean=0.420\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000]\n",
      "(50, 9)\n",
      "i=9 accMean=0.340\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "(50, 10)\n",
      "i=10 accMean=0.460\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "(50, 11)\n",
      "i=11 accMean=0.400\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "(50, 12)\n",
      "i=12 accMean=0.300\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000]\n",
      "(50, 13)\n",
      "i=13 accMean=0.360\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000]\n",
      "(50, 14)\n",
      "i=14 accMean=0.280\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000 0.000]\n",
      "(50, 15)\n",
      "i=15 accMean=0.360\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000]\n",
      "(50, 16)\n",
      "i=16 accMean=0.380\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000]\n",
      "(50, 17)\n",
      "i=17 accMean=0.400\n",
      "[0.918 0.076 0.005 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "(50, 18)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1b5829b637c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_ss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitNets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_ss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maccMean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunLeaveOneOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_ss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i={0:} accMean={1:0.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccMean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-7f213e36c365>\u001b[0m in \u001b[0;36mrunLeaveOneOut\u001b[0;34m(data, labels_onehot, epochs, verbose)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_ss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mallXBut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallYBut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moneX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moneY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallButOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallXBut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallYBut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moneX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moneY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-abffe8fa8a43>\u001b[0m in \u001b[0;36mrun_training_loop\u001b[0;34m(data_ss, labels_onehot, num_epochs, opt_state, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_ss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mepoch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         if verbose: print(\"Epoch {} | T: {:0.2f} | loss: {:0.3f} \".format(epoch+1, epoch_time,\n",
      "\u001b[0;32m~/anaconda3/envs/dml3.8/lib/python3.8/site-packages/jax/experimental/optimizers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data, xs)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mOptimizerState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpacked_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtree_defs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     lambda data, xs: OptimizerState(xs[0], data[0], data[1]))\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,data_np.shape[0]):\n",
    "    pca=PCA(i,whiten=True)\n",
    "    data_ss=pca.fit_transform(data_np)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(data_ss.shape)\n",
    "    net,netTest,opt_state,get_params,opt_update=initNets(data_ss)\n",
    "    accMean=runLeaveOneOut(data_ss,labels_onehot,epochs=10000,verbose=False)\n",
    "    print(\"i={0:} accMean={1:0.3f}\".format(i,accMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-poison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-television",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
