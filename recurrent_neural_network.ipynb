{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y=W*x+U*y\n",
    "Si V=concat(W,U) y z=concat(x,y) se cumple que\n",
    "y=Vz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   1.   1. ]\n",
      " [-2.   4.5  6.2]\n",
      " [ 0.   0.   0. ]]\n",
      "p= [[  2.6   10.4   12.44]]\n",
      "dif= [[ 4.4  -1.4   5.56]]\n",
      "x= [[  1.     1.     1.  ]\n",
      " [ -2.     4.5    6.2 ]\n",
      " [  2.6   10.4   12.44]]\n",
      "w= [[ 5.01712   1.238744  0.1     ]] iw= [[ 17.12   38.744  -0.   ]]\n",
      "p= [[  2.799632   11.631468   13.9413328]]\n",
      "dif= [[ 4.200368  -2.631468   4.0586672]]\n",
      "x= [[  1.          1.          1.       ]\n",
      " [ -2.          4.5         6.2      ]\n",
      " [  2.799632   11.631468   13.9413328]]\n",
      "w= [[ 5.02837513  1.24858679  0.16808702]] iw= [[ 11.2551344    9.84278928  68.08701914]]\n",
      "p= [[  3.00178335  12.60211447  15.1129703 ]]\n",
      "dif= [[ 3.99821665 -3.60211447  2.8870297 ]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.00178335  12.60211447  15.1129703 ]]\n",
      "w= [[ 5.0349414   1.23597406  0.18717641]] iw= [[  6.56626375 -12.61272855  19.08939582]]\n",
      "p= [[  3.12485632  12.95564328  15.52677217]]\n",
      "dif= [[ 3.87514368 -3.95564328  2.47322783]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.12485632  12.95564328  15.52677217]]\n",
      "w= [[ 5.03972685  1.21554072  0.1854978 ]] iw= [[  4.78545645 -20.43333918  -1.67861791]]\n",
      "p= [[  3.18829938  12.91290339  15.45626136]]\n",
      "dif= [[ 3.81170062 -3.91290339  2.54373864]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.18829938  12.91290339  15.45626136]]\n",
      "w= [[ 5.04461193  1.19662015  0.18692357]] iw= [[  4.88507175 -18.92057389   1.42577323]]\n",
      "p= [[  3.24733993  12.84312859  15.3527964 ]]\n",
      "dif= [[ 3.75266007 -3.84312859  2.6472036 ]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.24733993  12.84312859  15.3527964 ]]\n",
      "w= [[ 5.0497254   1.17984667  0.19343262]] iw= [[  5.11347015 -16.77347296   6.50905246]]\n",
      "p= [[  3.31817353  12.84331548  15.33450645]]\n",
      "dif= [[ 3.68182647 -3.84331548  2.66549355]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.31817353  12.84331548  15.33450645]]\n",
      "w= [[ 5.05473341  1.16358165  0.20047008]] iw= [[  5.00800908 -16.26502524   7.03745381]]\n",
      "p= [[  3.39276461  12.86555127  15.34304931]]\n",
      "dif= [[ 3.60723539 -3.86555127  2.65695069]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.39276461  12.86555127  15.34304931]]\n",
      "w= [[ 5.05953068  1.14730893  0.20660201]] iw= [[  4.79726962 -16.27271446   6.13193201]]\n",
      "p= [[  3.46586479  12.88046962  15.34275088]]\n",
      "dif= [[ 3.53413521 -3.88046962  2.65724912]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.46586479  12.88046962  15.34275088]]\n",
      "w= [[ 5.0641525   1.13119806  0.21227483]] iw= [[  4.62182944 -16.11087827   5.67282484]]\n",
      "p= [[  3.53747226  12.8887433   15.33446034]]\n",
      "dif= [[ 3.46252774 -3.8887433   2.66553966]]\n",
      "x= [[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.53747226  12.8887433   15.33446034]]\n",
      "w= [[ 5.06863115  1.11540195  0.21789188]] iw= [[  4.47864819 -15.79610892   5.61704789]]\n",
      "[[ 5.06863115  1.11540195  0.21789188]]\n",
      "[[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  3.53747226  12.8887433   15.33446034]]\n"
     ]
    }
   ],
   "source": [
    "def setPreviousY(x,p):\n",
    "    x[2,:]=p\n",
    "#Matrix version of linear model\n",
    "def fm(x):\n",
    "    y=w*x\n",
    "    return y\n",
    "#Initial weights\n",
    "#            b    w   u\n",
    "w=np.matrix([5.0,1.2,0.1])\n",
    "#Data, first row are ones for bias\n",
    "x=np.matrix([[ 1.0, 1.0, 1.0], #bias data always 1\n",
    "             [-2.0, 4.5, 6.2], #actual data\n",
    "             [ 0.0, 0.0, 0.0]])#previous y values\n",
    "setPreviousY(x,np.matrix([ 0.0, 0.0, 0.0]))\n",
    "print(x)\n",
    "y=np.matrix( [ 7.0, 9.0,18.0] )#Matrix version of Gradient descent\n",
    "#Loss function\n",
    "def L(w):\n",
    "    dif=y-fm(x)\n",
    "    l=dif*dif.T\n",
    "    return l[0,0]\n",
    "#Loss gradient is a vector with same dimensions as w\n",
    "def dL(w):\n",
    "    p=fm(x) #prediction\n",
    "    print(\"p=\",p)\n",
    "    dif=y-p #difference\n",
    "    print(\"dif=\",dif)\n",
    "    dL_w=-2*dif*x.T\n",
    "    #update data but previous only\n",
    "    setPreviousY(x,p)\n",
    "    print(\"x=\",x)\n",
    "    return dL_w\n",
    "#Learning rate\n",
    "a=0.01\n",
    "#Initial weights\n",
    "#            b    w   u\n",
    "w=np.matrix([5.0,1.2,0.1])\n",
    "for i in range(10):\n",
    "    iw=-dL(w)\n",
    "    w=w+a*iw\n",
    "    print(\"w=\",w,\"iw=\",iw)\n",
    "print(w)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   1.   1. ]\n",
      " [-2.   4.5  6.2]\n",
      " [ 0.   0.   0. ]]\n",
      "[[  7.   9.  18.]]\n",
      "****** EPOCH 0\n",
      "p= [[ 2.6]]\n",
      "dif= [[ 4.4]]\n",
      "x= [[ 1.]\n",
      " [-2.]\n",
      " [ 0.]]\n",
      "w= [[ 5.0088  1.1824  0.1   ]] iw= [[ -8.8  17.6   0. ]]\n",
      "p= [[ 10.5896]]\n",
      "dif= [[-1.5896]]\n",
      "x= [[ 1. ]\n",
      " [ 4.5]\n",
      " [ 2.6]]\n",
      "w= [[ 5.0056208   1.1680936   0.09173408]] iw= [[  3.1792   14.3064    8.26592]]\n",
      "p= [[ 13.21922833]]\n",
      "dif= [[ 4.78077167]]\n",
      "x= [[  1.    ]\n",
      " [  6.2   ]\n",
      " [ 10.5896]]\n",
      "w= [[ 5.01518234  1.22737517  0.192987  ]] iw= [[  -9.56154333  -59.28156866 -101.25291928]]\n",
      "c= 3.59012388881\n",
      "****** EPOCH 1\n",
      "p= [[ 2.56043201]]\n",
      "dif= [[ 4.43956799]]\n",
      "x= [[ 1.]\n",
      " [-2.]\n",
      " [ 0.]]\n",
      "w= [[ 5.02406148  1.2096169   0.192987  ]] iw= [[ -8.87913599  17.75827198   0.        ]]\n",
      "p= [[ 10.9614676]]\n",
      "dif= [[-1.9614676]]\n",
      "x= [[ 1.        ]\n",
      " [ 4.5       ]\n",
      " [ 2.56043201]]\n",
      "w= [[ 5.02013854  1.19196369  0.18294259]] iw= [[  3.92293521  17.65320844  10.04440886]]\n",
      "p= [[ 14.41563269]]\n",
      "dif= [[ 3.58436731]]\n",
      "x= [[  1.       ]\n",
      " [  6.2      ]\n",
      " [ 10.9614676]]\n",
      "w= [[ 5.02730728  1.23640984  0.26152244]] iw= [[ -7.16873462 -44.44615465 -78.57985231]]\n",
      "c= 3.3284676362\n",
      "****** EPOCH 2\n",
      "p= [[ 2.55448759]]\n",
      "dif= [[ 4.44551241]]\n",
      "x= [[ 1.]\n",
      " [-2.]\n",
      " [ 0.]]\n",
      "w= [[ 5.0361983   1.21862779  0.26152244]] iw= [[ -8.89102481  17.78204963   0.        ]]\n",
      "p= [[ 11.18807921]]\n",
      "dif= [[-2.18807921]]\n",
      "x= [[ 1.        ]\n",
      " [ 4.5       ]\n",
      " [ 2.55448759]]\n",
      "w= [[ 5.03182215  1.19893508  0.2503436 ]] iw= [[  4.37615842  19.69271288  11.17884238]]\n",
      "p= [[ 15.26608367]]\n",
      "dif= [[ 2.73391633]]\n",
      "x= [[  1.        ]\n",
      " [  6.2       ]\n",
      " [ 11.18807921]]\n",
      "w= [[ 5.03728998  1.23283564  0.31151815]] iw= [[ -5.46783265 -33.90056245 -61.17454482]]\n",
      "c= 3.12250264733\n",
      "++++++++ END\n",
      "[[ 5.03728998  1.23283564  0.31151815]]\n",
      "[[  1.           1.           1.        ]\n",
      " [ -2.           4.5          6.2       ]\n",
      " [  0.           2.55448759  11.18807921]]\n",
      "[[  7.   9.  18.]]\n",
      "[[  2.55448759  11.18807921  15.26608367]]\n",
      "[3.5901238888106661, 3.3284676362038597, 3.1225026473306081]\n"
     ]
    }
   ],
   "source": [
    "#Let treate the matrix data as a sequence colum by colum\n",
    "#this version doesn't unroll but it seem to work, sure there is some problema\n",
    "\n",
    "#Matrix version of linear model\n",
    "def fm(x,w):\n",
    "    y=w*x\n",
    "    return y\n",
    "#Data, first row are ones for bias\n",
    "x=np.matrix([[ 1.0, 1.0, 1.0], #bias data always 1\n",
    "             [-2.0, 4.5, 6.2], #actual data\n",
    "             [ 0.0, 0.0, 0.0]])#previous y values\n",
    "setPreviousY(x,np.matrix([ 0.0, 0.0, 0.0]))\n",
    "print(x)\n",
    "y=np.matrix( [ 7.0, 9.0,18.0] )#Matrix version of Gradient descent\n",
    "print(y)\n",
    "#Loss function\n",
    "def L(w,x,y):\n",
    "    dif=y-fm(x)\n",
    "    l=dif*dif.T\n",
    "    return l[0,0]\n",
    "#Loss gradient is a vector with same dimensions as w\n",
    "def dL(w,x,y):\n",
    "    p=fm(x,w) #prediction\n",
    "    print(\"p=\",p)\n",
    "    dif=y-p #difference\n",
    "    print(\"dif=\",dif)\n",
    "    dL_w=-2*dif*x.T\n",
    "    print(\"x=\",x)\n",
    "    return dL_w,p\n",
    "#Learning rate\n",
    "a=0.001\n",
    "#Initial weights\n",
    "#            b    w   u\n",
    "w=np.matrix([5.0,1.2,0.1])\n",
    "epochs=3\n",
    "#save data\n",
    "X=[]\n",
    "P=np.zeros_like(y)\n",
    "C=[]\n",
    "for i in range(epochs):\n",
    "    print(\"****** EPOCH\",i)\n",
    "    p=0 #previous y\n",
    "    for t in range(x.shape[1]):\n",
    "        xt=x[:,t]\n",
    "        xt[2,0]=p #update data with previous values\n",
    "        yt=y[:,t]\n",
    "        iw,p=dL(w,xt,yt)\n",
    "        P[0,t]=p\n",
    "        w=w-a*iw\n",
    "        print(\"w=\",w,\"iw=\",iw)\n",
    "    c=np.sum(np.abs(y-P))/float(x.shape[1])\n",
    "    print(\"c=\",c)\n",
    "    C.append(c)\n",
    "print(\"++++++++ END\")\n",
    "print(w)\n",
    "print(x)\n",
    "print(y)\n",
    "print(P)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-71e9c13ab6c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Data, first row are ones for bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m x=np.matrix([[ 1.0, 1.0, 1.0], #bias data always 1\n\u001b[0m\u001b[1;32m      8\u001b[0m              \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#actual data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m              [ 0.0, 0.0, 0.0]])#previous y values\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#Lets unroll and then do \n",
    "#Matrix version of linear model\n",
    "def fm(x,w):\n",
    "    y=w*x\n",
    "    return y\n",
    "#Data, first row are ones for bias\n",
    "x=np.matrix([[ 1.0, 1.0, 1.0], #bias data always 1\n",
    "             [-2.0, 4.5, 6.2], #actual data\n",
    "             [ 0.0, 0.0, 0.0]])#previous y values\n",
    "setPreviousY(x,np.matrix([ 0.0, 0.0, 0.0]))\n",
    "print(x)\n",
    "y=np.matrix( [ 7.0, 9.0,18.0] )#Matrix version of Gradient descent\n",
    "print(y)\n",
    "#Loss function\n",
    "def L(w,x,y):\n",
    "    dif=y-fm(x,w)\n",
    "    l=dif*dif.T\n",
    "    return l[0,0]\n",
    "#Loss gradient is a vector with same dimensions as w\n",
    "def dL(w,x,y):\n",
    "    p=fm(x,w) #prediction\n",
    "    print(\"p=\",p)\n",
    "    dif=y-p #difference\n",
    "    print(\"dif=\",dif)\n",
    "    dL_w=-2*dif*x.T\n",
    "    print(\"x=\",x)\n",
    "    return dL_w,p\n",
    "#Learning rate\n",
    "a=0.001\n",
    "#Initial weights\n",
    "#            b    w   u\n",
    "w=np.matrix([5.0,1.2,0.1])\n",
    "epochs=1000\n",
    "#save data\n",
    "X=[]\n",
    "P=np.zeros_like(y)\n",
    "C=[]\n",
    "xt,pt={},{}\n",
    "pt[-1]=np.matrix(np.zeros_like(y[:,0]))\n",
    "loss=0\n",
    "for i in range(epochs):\n",
    "    print(\"****** EPOCH\",i)\n",
    "    #Forward unroll\n",
    "    for t in range(x.shape[1]):\n",
    "        xt[t]=x[:,t]\n",
    "        xt[t][2,0]=pt[t-1] #update data with previous values (for training is better use actual values of y)\n",
    "        pt[t]=fm(xt[t],w)\n",
    "        loss+=L(w,xt[t],y[0,t])\n",
    "    print(\"xt=\",xt)\n",
    "    print(\"pt=\",pt)\n",
    "    for t in reversed(range(x.shape[1])):       \n",
    "        iw,pt[t]=dL(w,xt[t],yt[t])\n",
    "        P[0,t]=p\n",
    "        w=w-a*iw\n",
    "        print(\"w=\",w,\"iw=\",iw)\n",
    "    c=np.sum(np.abs(y-P))/float(x.shape[1])\n",
    "    print(\"c=\",c)\n",
    "    C.append(c)\n",
    "print(\"++++++++ END\")\n",
    "print(w)\n",
    "print(x)\n",
    "print(y)\n",
    "print(P)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
