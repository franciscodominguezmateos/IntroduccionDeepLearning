{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Francisco Dominguez Mateos\n",
    "# 13/06/2020\n",
    "# from: https://www.dlology.com/blog/how-to-do-real-time-trigger-word-detection-with-keras/\n",
    "#       https://www.coursera.org/lecture/nlp-sequence-models/trigger-word-detection-Li4ts\n",
    "#       https://github.com/Tony607/Keras-Trigger-Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c anaconda pyaudio --yes\n",
    "#!conda install -c conda-forge pydub --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 5511, 101)]       0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1375, 196)         297136    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1375, 196)         784       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1375, 196)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1375, 196)         0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 1375, 128)         125184    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1375, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1375, 128)         512       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 1375, 128)         99072     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1375, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1375, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1375, 128)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 1375, 1)           129       \n",
      "=================================================================\n",
      "Total params: 523,329\n",
      "Trainable params: 522,425\n",
      "Non-trainable params: 904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Step 1: CONV layer\n",
    "    X = Conv1D(196, kernel_size=15, strides=4)(X_input)   # CONV1D\n",
    "    X = BatchNormalization()(X)                           # Batch normalization\n",
    "    X = Activation('relu')(X)                             # ReLu activation\n",
    "    X = Dropout(0.2)(X)                                   # dropout (use 0.8)\n",
    "\n",
    "    # Step 2: First GRU Layer\n",
    "    X = GRU(units = 128, return_sequences = True)(X)      # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.2)(X)                                   # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                           # Batch normalization\n",
    "    \n",
    "    # Step 3: Second GRU Layer\n",
    "    X = GRU(units = 128, return_sequences = True)(X)      # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.2)(X)                                   # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                           # Batch normalization\n",
    "    X = Dropout(0.2)(X)                                   # dropout (use 0.8)\n",
    "    \n",
    "    # Step 4: Time-distributed dense layer\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
    "    model = Model(inputs = X_input, outputs = X)    \n",
    "    return model  \n",
    "\n",
    "Tx = 5511 # The number of time steps input to the model from the spectrogram\n",
    "n_freq = 101 # Number of frequencies input to the model at each time step of the spectrogram\n",
    "\n",
    "model = model(input_shape = (Tx, n_freq))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GRU(reset_after=False) is not compatible with GRU(reset_after=True)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-55c99695596b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/tr_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dml3.8/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m       if (h5py is not None and\n\u001b[1;32m    205\u001b[0m           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 206\u001b[0;31m         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                 compile)\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml3.8/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml3.8/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     weight_values = preprocess_weights_for_loading(\n\u001b[0m\u001b[1;32m    700\u001b[0m         layer, weight_values, original_keras_version, original_backend)\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml3.8/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[0;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m   \u001b[0;31m# convert CuDNN layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_rnn_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dml3.8/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36m_convert_rnn_weights\u001b[0;34m(layer, weights)\u001b[0m\n\u001b[1;32m    569\u001b[0m       \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'GRU(reset_after=False)'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s is not compatible with %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CuDNNGRU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_gru_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_cudnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GRU(reset_after=False) is not compatible with GRU(reset_after=True)"
     ]
    }
   ],
   "source": [
    "model = load_model('./models/tr_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_new_triggerword(predictions, chunk_duration, feed_duration, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Function to detect new trigger word in the latest chunk of input audio.\n",
    "    It is looking for the rising edge of the predictions data belongs to the\n",
    "    last/latest chunk.\n",
    "    \n",
    "    Argument:\n",
    "    predictions -- predicted labels from model\n",
    "    chunk_duration -- time in second of a chunk\n",
    "    feed_duration -- time in second of the input to model\n",
    "    threshold -- threshold for probability above a certain to be considered positive\n",
    "\n",
    "    Returns:\n",
    "    True if new trigger word detected in the latest chunk\n",
    "    \"\"\"\n",
    "    predictions = predictions > threshold\n",
    "    chunk_predictions_samples = int(len(predictions) * chunk_duration / feed_duration)\n",
    "    chunk_predictions = predictions[-chunk_predictions_samples:]\n",
    "    level = chunk_predictions[0]\n",
    "    for pred in chunk_predictions:\n",
    "        if pred > level:\n",
    "            return True\n",
    "        else:\n",
    "            level = pred\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queue to communiate between the audio callback and main thread\n",
    "q = Queue()\n",
    "\n",
    "run = True\n",
    "\n",
    "silence_threshold = 100\n",
    "\n",
    "# Run the demo for a timeout seconds\n",
    "timeout = time.time() + 0.5*60  # 0.5 minutes from now\n",
    "\n",
    "# Data buffer for the input wavform\n",
    "data = np.zeros(feed_samples, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    if np.abs(data0).mean() < silence_threshold:\n",
    "        sys.stdout.write('-')\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > feed_samples:\n",
    "        data = data[-feed_samples:]\n",
    "        # Process data async by sending a queue.\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = get_audio_input_stream(callback)\n",
    "stream.start_stream()\n",
    "\n",
    "\n",
    "try:\n",
    "    while run:\n",
    "        data = q.get()\n",
    "        spectrum = get_spectrogram(data)\n",
    "        preds = detect_triggerword_spectrum(spectrum)\n",
    "        new_trigger = has_new_triggerword(preds, chunk_duration, feed_duration)\n",
    "        if new_trigger:\n",
    "            sys.stdout.write('1')\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False\n",
    "        \n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
